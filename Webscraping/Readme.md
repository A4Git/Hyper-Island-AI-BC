## The goal 
**The goal is to scrape the data from all the newsletters into an dataframe, sort only the last part of each newsletter, ie. the question:**
![Question](https://github.com/A4Git/Hyper-Island-AI-BC/blob/59f93f4e070b9356c07882ae321835bd13e23f35/Webscraping/img/q1.png)


**The end result we are aming for is a csv file that looks like this one:**
![Goal](https://github.com/A4Git/Hyper-Island-AI-BC/blob/59f93f4e070b9356c07882ae321835bd13e23f35/Webscraping/img/bild_3.jpeg)


### The Scope

The scope of this notebook is to learn by doing. It's a barebone notebook with some code to get you started, some references and the end result we are aiming for. The rest (aka. googling, trying out code, and debugging is up to you, and that is in my opinion the best way to learn). Whenever possible, **write code**, even when you find it online as the ctrl +c /ctrl +v does not compute into learning. 


### The outline of this project include the following steps: 

* [ ] Downloading web pages using the requests library
* [ ] Inspecting the HTML source code of a web page
* [ ] Parsing parts of a website using Beautiful Soup
* [ ] Writing parsed information into CSV files

**First:**
1. Get it done (make a draft that runs without errors)
2. Then make it nice ( iterate over the draft and try to make it explainable, comment the code, give some context, etc.)
